# ğŸ“§ Spam Detector using Machine Learning
## ğŸ“Œ Overview
This project is a machine learning-based spam detection system that classifies messages as **spam** or **ham** with **98% accuracy**.  
It uses natural language processing (NLP) techniques for text preprocessing and multiple ML algorithms for classification.
## âœ¨ Features
- ğŸ“Š High accuracy (98%) with robust F1 score
- ğŸ“ Preprocessing: tokenization, stopword removal, stemming
- ğŸ”¢ Feature extraction using Bag of Words (BoW) and TF-IDF
- ğŸ¤– Models: Logistic Regression, NaÃ¯ve Bayes, SVM
- ğŸ“ˆ Evaluation using Precision, Recall, and F1 score
## ğŸ“‚ Dataset
The dataset used is the [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) from UCI Machine Learning Repository.

- **Total Messages:** 5,574  
- **Labels:** Spam / Ham
## ğŸ›  Tech Stack
- **Language:** Python
- **Libraries:** Pandas, NumPy, Scikit-learn, NLTK
- **Jupyter Notebook** for development
## âš™ï¸ Workflow
1. **Load Dataset** â†’ Read the dataset into a DataFrame.
2. **Data Preprocessing** â†’ Tokenization, stopword removal, stemming.
3. **Feature Extraction** â†’ Convert text into numerical vectors using BoW and TF-IDF.
4. **Model Training** â†’ Train Logistic Regression, NaÃ¯ve Bayes, and SVM models.
5. **Model Evaluation** â†’ Calculate Accuracy, Precision, Recall, and F1 score.
6. **Comparison & Selection** â†’ Choose the best model for final predictions.
## ğŸ“Š Model Performance
| Model                | Accuracy | Precision | Recall | F1 Score |
|----------------------|----------|-----------|--------|----------|
| Logistic Regression  | 0.98     | 0.98      | 0.97   | 0.97     |
| NaÃ¯ve Bayes          | 0.97     | 0.96      | 0.95   | 0.96     |
| SVM                  | 0.98     | 0.98      | 0.97   | 0.97     |

**Best Model:** Logistic Regression & SVM (tied at 98% accuracy)
## ğŸ“‘ Classification Report
              precision    recall  f1-score   support

         ham       0.98      1.00      0.99      1205
        spam       0.99      0.94      0.96       188

    accuracy                           0.98      1393
   macro avg       0.98      0.97      0.97      1393
weighted avg       0.98      0.98      0.98      1393
